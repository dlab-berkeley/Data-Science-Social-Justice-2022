{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK1XGvB8yAMo"
   },
   "source": [
    "# Data Science for Social Justice Workshop: Optional Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reddit API\n",
    "\n",
    "In this notebook, we'll access the Reddit API to get your own data.\n",
    "\n",
    "The Reddit API allows you to do lots of things, such as automatically post as a user. It also allows you to retrieve data from Reddit, such as subreddit posts and comments. \n",
    "\n",
    "There are restrictions in place: Reddit's API only allows you to retrieve 1000 posts (and associated comments) per task. While we can create a script that takes note of the timecodes of posts so as to scrape the entiry of a subreddit in multiple tasks, for now we will just download 1000 posts from our dataset (or fewer, if your subreddit has fewer than 1000 posts).\n",
    "\n",
    "Follow these steps to get started:\n",
    "\n",
    "1. **Sign Up.** First, you will need to sign up with Reddit to run some of the code. Go to http://www.reddit.com and **sign up** for an account.\n",
    "\n",
    "2. **Create an App.** Go to [this page](https://ssl.reddit.com/prefs/apps/) and click on the `are you a developer? create an app` button at the bottom.\n",
    "\n",
    "3. **Fill Out the Form.** Fill out the form that appears. For the name, you can enter whatever you'd like. Select \"script\". Enter the redirect uri as shown. Otherwise, you can leave everything else blank. Then, click \"create app\".\n",
    "\n",
    "![redditapi](../../img/reddit_api.png)\n",
    "\n",
    "4. **Note API Credentials.** You should see a new box appear, with some important information. This includes:\n",
    "    - Client ID: A 14-character string (at least) listed just under “personal use script” for the desired developed application.\n",
    "    - Client Secret: A 27-character string (at least) listed adjacent to secret for the application.\n",
    "    - Username: The username of the Reddit account used to register the application.\n",
    "    - Password: This is not shown here, but you should remember your password to your account.\n",
    "    \n",
    "![redditapi2](../../img/reddit_api2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Using `praw`\n",
    "\n",
    "Even though we're set up with the API, we still need to have a way to use Python to interface with the API. Luckily, this is already done for us via the Python Reddit API Wrapper: `praw`. This is a package we can download and use.\n",
    "\n",
    "Install `praw`, and fill out your details below to create a `reddit` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='YOUR_CLIENT_NAME_HERE',\n",
    "                     client_secret='YOUR_CLIENT_SECRET_HERE',\n",
    "                     password='YOUR_REDDIT_PSW_HERE',\n",
    "                     user_agent='Get Reddit data 1.0 by /u/YOUR_REDDIT_NAME_HERE',\n",
    "                     username='YOUR_REDDIT_USERNAME_HERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxIh6VqnyAMs"
   },
   "source": [
    "## Getting Data with the Reddit API\n",
    "\n",
    "For the purpose of this exercise, we'll download Reddit data in one file, but it's common practice to download posts and comments in two different relational databases.\n",
    "\n",
    "First, we enter the user details of the app we just created. Then, we run a function that retrieves the post and its associated metadata, as well as the comments. We'll save the information in a CSV.\n",
    "\n",
    "**Note:** you might want to add other metadata elements to your function, or organize it differently. For example, Reddit submissions also have a \"spoiler\" attribute that indicates whether a response is a spoiler (relevant if you're gathering data from a movie or game-related subreddit!). For a list of all the attibutes you can use, check:\n",
    "\n",
    "* [Submissions/Posts](https://praw.readthedocs.io/en/latest/code_overview/models/submission.html)\n",
    "* [Comments](https://praw.readthedocs.io/en/latest/code_overview/models/comment.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjsFCrCCyAMt"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def get_reddit_data(subreddit_name, max_count):\n",
    "    \"\"\"Scrapes Reddit submissions and comments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subreddit_name : string\n",
    "        The subreddit name.\n",
    "    max_count : int\n",
    "        The maximum number of posts to query.\n",
    "    \"\"\"\n",
    "    filename = subreddit_name + '_' + str(max_count) + '_' + datetime.now().strftime('%Y%m%d') + '.csv'\n",
    "    # Setting up a csv writer and write the first row \n",
    "    writer = csv.writer(open(filename, 'wt', encoding = 'utf-8'))\n",
    "    writer.writerow(['idstr', 'created', 'created_datetime', 'nsfw', 'flair_text', 'flair_css_class',\n",
    "                     'author', 'title', 'selftext', 'score', 'upvote_ratio', \n",
    "                     'distinguished', 'textlen', 'num_comments', 'top_comments'])   \n",
    "    item_count = 0\n",
    "    comment_count = 0\n",
    "    for submission in reddit.subreddit(subreddit_name).hot(limit=None): \n",
    "        try:\n",
    "            item_count += 1\n",
    "            idstr = submission.id\n",
    "            created = submission.created\n",
    "            created_datetime = datetime.fromtimestamp(created).strftime('%Y' + '-' + '%m' + '-' + '%d')\n",
    "            nsfw = submission.over_18\n",
    "            flair_text = submission.link_flair_text\n",
    "            flair_css_class = submission.link_flair_css_class\n",
    "            author = submission.author\n",
    "            title = submission.title\n",
    "            selftext = submission.selftext\n",
    "            score = submission.score\n",
    "            upvote_ratio = submission.upvote_ratio\n",
    "            distinguished = submission.distinguished\n",
    "            textlen = len(submission.selftext)\n",
    "            num_comments = submission.num_comments\n",
    "            comment_list = []\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            for comment in submission.comments.list():\n",
    "                if comment.author != None:\n",
    "                    comment_count += 1\n",
    "                    comment_list.append(comment.body)\n",
    "            comments = ' '.join(comment_list)\n",
    "            writer.writerow((idstr, created, created_datetime, nsfw, flair_text, flair_css_class,\n",
    "                             author, title, selftext, score, upvote_ratio,\n",
    "                             distinguished, textlen, num_comments, comments))\n",
    "            print('.', end='', flush=True)\n",
    "        except:\n",
    "            print('Error found--resuming...')\n",
    "        if item_count == max_count:\n",
    "            break\n",
    "\n",
    "    if item_count > 0:\n",
    "        print('Done!' + '\\n' + 'Found ' + str(item_count) + ' posts' + \n",
    "              '\\n' + 'Found ' + str(comment_count) + ' comments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're set up, let's get our data. Change \"amitheasshole\" in the function call below to your preferred subreddit name (you can find it in Reddit's URL, after \"/r/\").\n",
    "\n",
    "In the `for` loop statement above, instead of using `.hot` (currently popular posts), you can also try `.top` (top scoring posts), `.new` (the latest posts), or `.controversial` (posts with a lot of up- and downvotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reddit_data('amitheasshole', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function wrote to a file for us, which we can access in this folder."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 2 OPTIONAL - Reddit API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
