{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNXZ3qG4plMW"
   },
   "source": [
    "# Data Science for Social Justice Workshop: Module 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtIBMFnNrQlL"
   },
   "source": [
    "## Language Biases and Word Embeddings\n",
    "\n",
    "Language carries implicit biases, functioning both as a reflection and a perpetuation of stereotypes that people carry with them. Using natural language processing tools, we can trace these biases in the many language datasets to be found online.\n",
    "\n",
    "One way to discover language biases is via word embeddings. In order to do so, we first need to postulate concepts for terms along which we might expect biases to exist. For example, humans often associate words with masculinity or femininity, which reflects both a normative construction of a gender binary, as well as stereotypes *within* that binary. Word embeddings provide us word vectors for many terms, including \"male\" and \"female\", as well as other words that may be more strongly associated with the concepts of \"male\" and \"female\", as reflected in language use. We can attempt to quantify this directly using notions of distance with word embeddings.\n",
    "\n",
    "Specifically, we develop *target concepts* for the terms we aim to identify biases along (e.g., \"male\" and \"female\"). Then, we can then compute relative similarities of other word vectors – particularly, words that act as evaluative attributes such as \"strong\" and \"sensitive\". These words can be categorised through clustering algorithms and labeled through a semantic analysis system into more general (conceptual) biases, yielding a broad picture of the biases present in a discourse community.\n",
    "\n",
    "This notebook is based off a paper examining language biases in Reddit: see [here](https://xfold.github.io/WE-GenderBiasVisualisationWeb/) for a web demo\n",
    "and [here](https://github.com/xfold/LanguageBiasesInReddit) for the full repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "import os\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5527,
     "status": "ok",
     "timestamp": 1647303381856,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "NrGY1R9J6sOi",
    "outputId": "446b4e6b-d909-4574-aff6-c8c1f471443a"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19056,
     "status": "ok",
     "timestamp": 1647300674056,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "e8vdjKO4fOh5",
    "outputId": "24d80e36-10eb-4ff4-facc-e0cb15bc4933"
   },
   "outputs": [],
   "source": [
    "# Change directory\n",
    "# We include two ../ because we want to go two levels up in the file structure\n",
    "os.chdir(\"../../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the Word Embeddings model we made in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2076396,
     "status": "ok",
     "timestamp": 1647308247064,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "5TRHImTC4wPs",
    "outputId": "120f9b7e-c7af-46c6-d34c-9281593b7072"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('aita.emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSbUVbC-rQlY"
   },
   "source": [
    "## Obtaining Biased Words Relative to Target Concepts\n",
    "\n",
    "We now run our method of finding biased words towards our target sets. We will be using functions in an external file - `utils.py` - which you are free to look through if you're interested. Otherwise, feel free to use the functions as desired.\n",
    "\n",
    "Given a vocabulary and two sets of target words (such as, in this case, those for *women* and *men*), we rank the words from least to most biased. As such, we obtain two ordered lists of the most biased words towards each target set, obtaining an overall view of the bias distribution in that particular community with respect to those two target sets. \n",
    "\n",
    "Here's what happening in the next block of code:\n",
    "- We calculate the centroid of a target set by averaging the embedding vectors in our target set (e.g. the vectors for `he, son, his, him, father, male` for our target concept `male`);\n",
    "- We calculate the cosine similarity between the vectors for all words in our vocabulary as compared to our two centroids (we also apply POS-filtering to only work with parts of speech we expect to be relevant);\n",
    "- We use a threshold based on standard deviation to determine how severe a bias needs to be before we include it;\n",
    "- We rank the words in the vocabulary of our word embeddings model based on their bias towards either target concept.\n",
    "\n",
    "Thus, the implicit hypothesis here is that word vectors much closer to the centroid of one target concept than the other are used more similarly with respect that concept. This, in effect, is an effort to quantify the bias of words used in general discourse within a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function to calculate biased words\n",
    "from utils import calculate_biased_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our target concept vectors. This is a critical choice: the centroid of these represents the concept at hand. What happens if you change the words included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = [\"sister\" , \"female\" , \"woman\" , \"girl\" , \"daughter\" , \"she\" , \"hers\" , \"her\"]\n",
    "target2 = [\"brother\" , \"male\" , \"man\" , \"boy\" , \"son\" , \"he\" , \"his\" , \"him\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11526,
     "status": "ok",
     "timestamp": 1647303428120,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "SIzdtQV5rQlh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[b1, b2] = calculate_biased_words(model, target1, target2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJpg5BDydlYT"
   },
   "source": [
    "Let's print some biases. Here you see the most-biased words towards our target concepts (1 being *women*, 2 being *men*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1647303438347,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "qc-9g8BErQll",
    "outputId": "93aa1d97-e9ad-4f17-9ce3-bef7d4079209"
   },
   "outputs": [],
   "source": [
    "print('Biased words towards target set 1')\n",
    "print([word for word in b1.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Biased words towards target set 2')\n",
    "print([word for word in b2.keys()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpk0lx2xplMf"
   },
   "source": [
    "## Visualizing Biases using $t$-SNE\n",
    "\n",
    "We now return to our dimensionality reduction technique, $t$-SNE, to try and visualize these biased words in a 2-d space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1647303476276,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "kET4XjgtplMf",
    "outputId": "7c00a295-5827-4a04-fb10-fe7eb6ce3532"
   },
   "outputs": [],
   "source": [
    "# prepare the datat for the tsne in order to create the plot\n",
    "\n",
    "labels1 = [] # labels = words\n",
    "y1 = []\n",
    "embs1 = []\n",
    "for k in clusters1:\n",
    "    labels1 += clusters1[k]\n",
    "embs1 = [model[j] for j in labels1]\n",
    "y1 = len(labels1)*[0]\n",
    "\n",
    "labels2 = []\n",
    "y2 = []\n",
    "embs2 = []\n",
    "for k in clusters2:\n",
    "    labels2 += clusters2[k]\n",
    "embs2 = [model[j] for j in labels2]\n",
    "y2 = len(labels2)*[1]\n",
    "\n",
    "labels = labels1 +labels2\n",
    "y      = y1 +y2\n",
    "embs   = embs1 + embs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=40,\n",
    "    n_components=2,\n",
    "    init='pca',\n",
    "    n_iter=5000,\n",
    "    random_state=23,\n",
    "    learning_rate='auto')\n",
    "\n",
    "X_tsne = tsne.fit_transform(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_idx = np.array([model.wv.key_to_index[key] for key in b1.keys()])\n",
    "target2_idx = np.array([model.wv.key_to_index[key] for key in b2.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target1 = X_tsne[target1_idx]\n",
    "X_target2 = X_tsne[target2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "ax.scatter(X_target1[:, 0], X_target1[:, 1], color='C0')\n",
    "ax.scatter(X_target2[:, 0], X_target2[:, 1], color='C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1647303482192,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "p4XnvP_1Wml4",
    "outputId": "ed532b21-140b-4f08-fdc6-2f7e658f7405"
   },
   "outputs": [],
   "source": [
    "# Note: the tsne should be estimated for all words in the model, otherwise the tsne dimensions won't be correct\n",
    "\n",
    "# if words apepar very close together, change random state to obtain better visual representations\n",
    "# dimensional reduction of T-SNE can be done through different ways; random_state determines which is taken\n",
    "tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=5000, random_state=42)\n",
    "X_tsne = tsne.fit_transform(embs) # X_tsne = [[1,2], [3,4], [5,6]]\n",
    "\n",
    "\n",
    "# split the X and Y coordinates\n",
    "embsx = [x[0] for x in X_tsne]\n",
    "embsy = [x[1] for x in X_tsne]\n",
    "color = ['blue' if i == 0 else 'red' for i in y]\n",
    "\n",
    "plt.figure(figsize=(16, 16)) \n",
    "for i in range(len(embs)):\n",
    "    plt.scatter(embsx[i],embsy[i], c=color[i])\n",
    "    plt.annotate( labels[i],\n",
    "                  xy=(embsx[i],embsy[i]),\n",
    "                  xytext=(6, 3),\n",
    "                  textcoords='offset points',\n",
    "                  ha='right',\n",
    "                  va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR_ONnWiHM0O"
   },
   "source": [
    "## Concordances of most-biased words\n",
    "\n",
    "We might want to engage in further analysis of the most interesting biased words in our data. To do so, let's reach back to the tools we looked at in the beginning of this course.\n",
    "\n",
    "Using NLTK, we can simply create a concordance view of the context in which the biased words appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23296,
     "status": "ok",
     "timestamp": 1647303687693,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "FHWhTuqgGgYL",
    "outputId": "52545d9d-c499-4e68-cb75-a8e8a65cd977"
   },
   "outputs": [],
   "source": [
    "# import NLTK Text class for convenience\n",
    "from nltk.text import Text\n",
    "\n",
    "def concordance_viewer(b_sort,width=115, top=10):\n",
    "    # sort by rank\n",
    "    b1_sort = sorted(b1.items(), key=lambda x: x[1]['rank'], reverse=False)\n",
    "    b2_sort = sorted(b2.items(), key=lambda x: x[1]['rank'], reverse=False)\n",
    "  \n",
    "    t_inp = input(\"Pick target set 1 or 2\")\n",
    "    if t_inp == \"1\":\n",
    "        target = b1_sort\n",
    "    elif t_inp == \"2\":\n",
    "        target = b2_sort\n",
    "    else:\n",
    "        t_inp = input(\"Pick target set 1 or 2\")\n",
    "    # print most biased words\n",
    "    print(\"{: >15} {: >5}\".format('WORD','RANK'))\n",
    "    for i in target[:top]:\n",
    "        row = [i[1]['word'], i[1]['rank']]\n",
    "        print(\"{: >15} {: >5}\".format(*row))\n",
    "    word_inp = input(\"Pick a biased word:\")\n",
    "    t = Text(docs_f)\n",
    "    t.concordance(word_inp, width=width)\n",
    "\n",
    "concordance_viewer(docs_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riINX9wVyFRJ"
   },
   "source": [
    "## Existing target sets - details\n",
    "\n",
    "*Gender target sets taken from Nosek, Banaji, and Greenwald 2002.*\n",
    "\n",
    "Female: `sister, female, woman, girl, daughter, she, hers, her`.\n",
    "\n",
    "Male: `brother, male, man, boy, son, he, his, him`.\n",
    "\n",
    "\n",
    "*Religion target sets taken from Garg et al. 2018.*\n",
    "\n",
    "Islam: `allah, ramadan, turban, emir, salaam, sunni, koran, imam, sultan, prophet, veil, ayatollah, shiite, mosque, islam, sheik, muslim, muhammad`.\n",
    "\n",
    "Christianity: `baptism, messiah, catholicism, resurrection, christianity, salva-tion, protestant, gospel, trinity, jesus, christ, christian, cross,catholic, church`.\n",
    "\n",
    "*Racial target sets taken from Garg et al. 2017*\n",
    "\n",
    "White last names: `harris, nelson, robinson, thompson, moore, wright, anderson, clark, jackson, taylor, scott, davis, allen, adams, lewis, williams, jones, wilson, martin, johnson`.\n",
    "\n",
    "Hispanic last names: `ruiz, alvarez, vargas, castillo, gomez, soto,gonzalez, sanchez, rivera, mendoza, martinez, torres, ro-driguez, perez, lopez, medina, diaz, garcia, castro, cruz`.\n",
    "\n",
    "Asian last names: `cho, wong, tang, huang, chu, chung, ng,wu, liu, chen, lin, yang, kim, chang, shah, wang, li, khan,singh, hong`.\n",
    "\n",
    "Russian last names: `gurin, minsky, sokolov, markov, maslow, novikoff, mishkin, smirnov, orloff, ivanov, sokoloff, davidoff, savin, romanoff, babinski, sorokin, levin, pavlov, rodin, agin`.\n",
    "\n",
    "\n",
    "*Career/family target sets taken from Garg et al. 2018.*\n",
    "\n",
    "Career: `executive, management, professional, corporation, salary, office, business, career`.\n",
    "\n",
    "Family: `home, parents, children, family, cousins, marriage, wedding, relatives.Math: math, algebra, geometry, calculus, equations, computation, numbers, addition`.\n",
    "\n",
    "\n",
    "*Arts/Science target sets taken from Garg et al. 2018.*\n",
    "\n",
    "Arts: `poetry, art, sculpture, dance, literature, novel, symphony, drama`.\n",
    "\n",
    "Science: `science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHCHMAPYTCVX"
   },
   "source": [
    "### Sources\n",
    "\n",
    "Nosek, B. A., Banaji, M. R., & Greenwald, A. G. (2002). Harvesting implicit group attitudes and beliefs from a demonstration web site. Group Dynamics, 6(1), 101–115. https://doi.org/10.1037/1089-2699.6.1.101\n",
    "\n",
    "Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2017). Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes, 1–33."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 4-2 Language Biases.ipynb",
   "provenance": [
    {
     "file_id": "1IgWcAC_gXRgwysSbqDr5ZIO9bxSVb6dl",
     "timestamp": 1601554822392
    },
    {
     "file_id": "1HXx9kevQetMI9pE0B9XCTFjgUHiGC4hm",
     "timestamp": 1594637500809
    }
   ]
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
