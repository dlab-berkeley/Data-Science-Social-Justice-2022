{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhs6S4deZFWW"
   },
   "source": [
    "# Data Science for Social Justice Workshop: Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJHDHrQPbjif"
   },
   "source": [
    "## Distant reading \n",
    "\n",
    "This notebook introduces some methods to engage in a simple distant reading using NLTK. We'll keep builing on our AITA DataFrame, discussing some simple ways to explore data. \n",
    "\n",
    "**After completing this notebook, you will be able to:**\n",
    "1. Do some more data operations in Pandas;\n",
    "2. Use NLTK's `Text()` object to perform some basic distant reading operations on a subreddit;\n",
    "\n",
    "There are several basic programming exercises scattered throughout for those who need it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6erwYIhh-cR"
   },
   "source": [
    "## Retrieving the dataset\n",
    "Let's get the data. Make sure you're in the \"Data\" directory when importing by running the magic command `%pwd`.\n",
    "If you're not in the right directory, use `os.chdir` to navigate there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22903,
     "status": "ok",
     "timestamp": 1647477678422,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "qqV-FJC9aHuT",
    "outputId": "9126a240-03b0-4403-eda9-afb71f673262"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# We include two ../ because we want to go two levels up in the file structure\n",
    "os.chdir('../../Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKZ6v_EzpUCi"
   },
   "source": [
    "Importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5173,
     "status": "ok",
     "timestamp": 1647477683593,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "WBLyQUt1qZRG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('aita_sub_top_sm_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuIFFo8clcwo"
   },
   "source": [
    "# 1. A couple more Pandas operations\n",
    "\n",
    "Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647477683596,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "zipTYx8rlbOo",
    "outputId": "b92d1d7b-071b-4223-f204-ffeb61a2c802"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW9zLOkjNok-"
   },
   "source": [
    "### Sorting a DF\n",
    "Using the `.sort_values()` method we can sort the df by particular columms. We use two parameters: the `by` parameter indicates by which column we want to sort, the `ascending` parameter indicated whether our sortation is in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647477683596,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "XogbDC5iNok-",
    "outputId": "73ab007f-8658-4813-db51-f2e3c2c3f3e7"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['score'], ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5TvYkHCqytt"
   },
   "source": [
    "One thing we often do when weâ€™re exploring a dataset is filtering the data based on a given condition. For example, we might need to find all the rows in our dataset where the score is over 500. We can use the `.loc[]` method to do so.\n",
    "\n",
    "`.loc[]` is a powerful method that can be used for all kinds of research purposes, if you want to filter or prune your dataset based on some condition. For more info, see [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html).\n",
    "\n",
    "For instance, if we only want rows with a score higher than 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647477683596,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "5DZbBlbkqytt",
    "outputId": "9e72f5f5-54d3-4042-fc42-da09d1398414"
   },
   "outputs": [],
   "source": [
    "df_top = df.loc[df.score >= 500]\n",
    "len(df_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also just access this data using `df[df.score >= 500]` (without the `.loc`). This is a bit shorter but has some drawbacks. See [this post](https://stackoverflow.com/questions/38886080/python-pandas-series-why-use-loc) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ux_P621yEM8"
   },
   "source": [
    "### Converting to datetime\n",
    "Did you ever wonder which format the \"created\" column is in? It is a Unix timestamp: the number of seconds that have elapsed since the Unix epoch, minus leap seconds; the Unix epoch is 00:00:00 UTC on 1 January 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1647477684307,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "WY9HSe-O1HSp",
    "outputId": "2f951a14-a2cd-4673-ea89-58589775798a"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(1207632114,unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Poupzh82zGt"
   },
   "source": [
    "Pandas allows us to create a new column evaluating the Unix timestamp to more readable datetimes using the `.to_datetime` method. \n",
    "\n",
    "Creating a new column in Pandas is as easy as using the bracket notation to write a new column name, then assigning it. In this case, we just use the `.to_datetime` method again to point to the entire \"created\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "error",
     "timestamp": 1647477684308,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "R6O7Y8cSzkmF",
    "outputId": "02b399de-c354-454d-a8aa-50c5f147260b"
   },
   "outputs": [],
   "source": [
    "df.insert(loc=3, column='created_datetime', value=pd.to_datetime(df['created'],unit='s'))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUt7QtgaHMrH"
   },
   "source": [
    "Let's save this new DF again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1965,
     "status": "ok",
     "timestamp": 1647477695219,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "ldh6Mp8yG_Wo"
   },
   "outputs": [],
   "source": [
    "df.to_csv('aita_sub_top_sm_lemmas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8TXz7BZzmv9"
   },
   "source": [
    "Our new \"created_datetime\" column is in a datetime format that Pandas can work with. We do so by calling the `DateTimeIndex` method: when we access the data in this column (also called a Series), the `DateTimeIndex` method turns it into a so-called Time Series. This is data type that allows for specific functionalities. For instance, we can check which years our Time Series data contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647477695220,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "fZDjb35G1dHH",
    "outputId": "47809871-72fc-4a68-9616-aba4e5009009"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pd.DatetimeIndex(df['created_datetime']).year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpKWfc8J-iHv"
   },
   "source": [
    "Looks like most of our data was written in 2021. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XTgmxK_pOFx"
   },
   "source": [
    "## Checking value counts\n",
    "We can also look at unique value counts for a column by running `value_counts()`, or easily visualize those counts using `hist()`.\n",
    "\n",
    "Let's have a look at two particularly interesting columns: \"flair_text\" and \"flair_css_class*. A flair, in Reddit, allows users to tag posts or usernames in certain subreddits to add context or humor. Here, the flair attached to the posts are created by moderators after the community votes on whether an OP was or wasn't the asshole. There are also other flairs such as \"No assholes here\" or \"Everyone sucks\". See [here](https://www.reddit.com/r/AmItheAsshole/wiki/faq) for more information.\n",
    "\n",
    "This community-driven data segmentation is quite helpful for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1639766457857,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "rn3_LO27pL9S",
    "outputId": "291cef5e-7263-4f34-87e3-4e88a7f1cd2a"
   },
   "outputs": [],
   "source": [
    "df.flair_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1647477699712,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "ekcw_5XopL9T",
    "outputId": "f2a0414d-d153-4d2d-f107-635635395826"
   },
   "outputs": [],
   "source": [
    "df.flair_css_class.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14etGJ7YzyZA"
   },
   "source": [
    "Let's see if we can find out whether people are considered assholes more frequently in particular months. \n",
    "We'll first create a new DF with just the submissions from 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647477699712,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "YsC_RdCVCd90",
    "outputId": "c281577b-184c-404c-c6d7-752bd83488a0"
   },
   "outputs": [],
   "source": [
    "df_2021 = df[pd.DatetimeIndex(df['created_datetime']).year == 2021]\n",
    "len(df_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dZntj-1ChhI"
   },
   "source": [
    "Using the `month_name()` method of `DateTimeIndex`, we can see which month each post was written in:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1647480745111,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "c5C94NvKXmPR",
    "outputId": "010dbcc9-28bb-4db5-f824-b64aee72d2f3"
   },
   "outputs": [],
   "source": [
    "months_array = pd.DatetimeIndex(df_2021['created_datetime']).month_name()\n",
    "months_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-96bWBCkbBtB"
   },
   "source": [
    "Now we have all we need to visualize the data. We will use the seaborn library to plot `df_2021`, using the `Datetimeindex` array we just created to separate counts on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1647481249192,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "UppM_rphbA-u",
    "outputId": "ca9bfea5-e90c-46b4-df19-f982c3d64a58"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(7,5)})\n",
    "\n",
    "p = sns.histplot(\n",
    "    data=df_2021, \n",
    "    x=months_array,\n",
    "    hue=\"flair_css_class\",\n",
    "    multiple=\"stack\"\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=70)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a2w-4BvmwYJ"
   },
   "source": [
    "## Calculating Type-token ratio\n",
    "Next, let's figure out the type-token ratio for our posts. Type-token ratio is a crude algorithm to gauge language complexity. First, we'll create a function that computes the TTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lo1Gz5hmwYJ"
   },
   "outputs": [],
   "source": [
    "def typeTokenRatio(tokens): \n",
    "    numTokens = len(tokens)\n",
    "    numTypes = len(set(tokens))\n",
    "    return numTypes/numTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPddUWELmwYM"
   },
   "source": [
    "Finally, we loop over the first 10 lemmatized submissions in our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647470189383,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "LN3t9CwKIvqy",
    "outputId": "7bb5dff4-00d2-4f08-d326-6e5b20e50b4d"
   },
   "outputs": [],
   "source": [
    "for x in df_2021['selftext'][:10]:\n",
    "    t = x.split()\n",
    "    print(typeTokenRatio(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yK1DCuAJbjkh"
   },
   "source": [
    "### Distant reading with NLTK `Text()`\n",
    "Let's have another look at our data. NLTK provides a `Text()` class, which is a \"wrapper\" that allows for inital exploration of texts. It supports counting, concordancing, collocation discovery, etc. \n",
    "\n",
    "Let's use our \"lemmas\" data we created in the last notebook. All we need to do is run `split()` on it to get our tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for row in df_2021['lemmas']:\n",
    "    total.extend(row.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1639772391510,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "cSnOXiTK8KjJ",
    "outputId": "fff12139-267a-4dbd-bc97-cef445f9d3c6"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.text import Text\n",
    "nltk.download('stopwords')\n",
    "\n",
    "aita_t = Text(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAdI-HgMbjkl"
   },
   "source": [
    "Let's print out the \"docstring\" of NLTK's `Text()` object, as well as all the things you can do with this object. Have a read through this to see what it allows you to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvexG4e7bjkm"
   },
   "outputs": [],
   "source": [
    "help(Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPatGDHDOpaU"
   },
   "source": [
    "### Concordances \n",
    "One of the most basic, but quite helpful, ways to quickly get an overview of the contexts in which a word appears is through a concordance view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1639772396041,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "nkDsXJkPbjkp",
    "outputId": "b9f3ec29-0485-438f-d1ab-628168a0a81e"
   },
   "outputs": [],
   "source": [
    "aita_t.concordance('mistake', width=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJxpt0sDgJ6A"
   },
   "source": [
    "### Collocations\n",
    "A collocation is a sequence of words that often appear together. The .collocations() method can find these in our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1639772405159,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "rWz18pTIgGtq",
    "outputId": "75eb133e-f126-412a-b8a4-ae9929bc6fe3"
   },
   "outputs": [],
   "source": [
    "aita_t.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np8M59BeDJll"
   },
   "source": [
    "### Word plotting\n",
    "Using the `dispersion_plot()` method we can easily visualize how often some word appears throughout the text. We have to feed it a list with several words.\n",
    "\n",
    "If our df is sorted by date we can see \"through time\" to see whether particular words start (dis)appearing in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1639772409569,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "_myUpUcqDIdh",
    "outputId": "86b411c5-743e-4781-f6a4-0f0cf10b647d"
   },
   "outputs": [],
   "source": [
    "aita_t.dispersion_plot([\"forgive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5q_G1GKkZSy"
   },
   "source": [
    "### Similar words\n",
    "Using the `.similar()` method we can look at \"distributional similarity\": finding other words which appear in the same contexts as the specified word.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4512,
     "status": "ok",
     "timestamp": 1639772469227,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "mWhoVtkrjBx_",
    "outputId": "10e2820d-d39e-4c3c-8799-42a5b78f5c3a"
   },
   "outputs": [],
   "source": [
    "aita_t.similar('girlfriend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOC5V4Pje0G9"
   },
   "source": [
    "### Common context\n",
    "The `.common_contexts()` method allows us to study the common context of two or more words. We must enclose these words in square brackets and round brackets, separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1639772490454,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "ccJOlE_se6Dp",
    "outputId": "1e9e204d-36d5-4dcd-8fd8-fac68833f0d2"
   },
   "outputs": [],
   "source": [
    "aita_t.common_contexts(['mom', 'dad'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 2 Distant Reading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
